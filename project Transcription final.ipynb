{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639089f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 2.1.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/waseek/.local/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/waseek/.local/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import whisper\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "import threading\n",
    "\n",
    "# Configuration\n",
    "MODEL_SIZE = \"tiny\"  # Default model size\n",
    "\n",
    "class TranscriptionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Media File Transcriber\")\n",
    "        self.root.geometry(\"600x450\")\n",
    "\n",
    "        # Variables\n",
    "        self.input_folder = tk.StringVar()\n",
    "        self.output_folder = tk.StringVar()\n",
    "        self.progress = tk.DoubleVar()\n",
    "        self.status = tk.StringVar(value=\"Ready\")\n",
    "        self.model_size = tk.StringVar(value=MODEL_SIZE)\n",
    "        self.translate_to_english = tk.BooleanVar(value=False)  \n",
    "\n",
    "        \n",
    "        self.create_widgets()\n",
    "\n",
    "        # Load Whisper model\n",
    "        self.model = None\n",
    "        self.load_model()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        \"\"\"Create and arrange GUI elements.\"\"\"\n",
    "        main_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Input Folder\n",
    "        ttk.Label(main_frame, text=\"Input Folder:\").grid(row=0, column=0, padx=10, pady=5, sticky=\"w\")\n",
    "        ttk.Entry(main_frame, textvariable=self.input_folder, width=50).grid(row=0, column=1, padx=10, pady=5)\n",
    "        ttk.Button(main_frame, text=\"Browse\", command=self.browse_input_folder).grid(row=0, column=2, padx=10, pady=5)\n",
    "\n",
    "        # Output Folder\n",
    "        ttk.Label(main_frame, text=\"Output Folder:\").grid(row=1, column=0, padx=10, pady=5, sticky=\"w\")\n",
    "        ttk.Entry(main_frame, textvariable=self.output_folder, width=50).grid(row=1, column=1, padx=10, pady=5)\n",
    "        ttk.Button(main_frame, text=\"Browse\", command=self.browse_output_folder).grid(row=1, column=2, padx=10, pady=5)\n",
    "\n",
    "        # Model Size Selection\n",
    "        ttk.Label(main_frame, text=\"Model Size:\").grid(row=2, column=0, padx=10, pady=5, sticky=\"w\")\n",
    "        model_options = [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
    "        model_menu = ttk.Combobox(main_frame, textvariable=self.model_size, values=model_options)\n",
    "        model_menu.grid(row=2, column=1, padx=10, pady=5)\n",
    "        model_menu.current(0)\n",
    "\n",
    "        # Translate Checkbox\n",
    "        self.translate_checkbox = ttk.Checkbutton(\n",
    "            main_frame, text=\"Translate to English\", variable=self.translate_to_english\n",
    "        )\n",
    "        self.translate_checkbox.grid(row=3, column=0, columnspan=2, padx=10, pady=5, sticky=\"w\")\n",
    "\n",
    "        # Progress Bar\n",
    "        self.progress_bar = ttk.Progressbar(main_frame, variable=self.progress, maximum=100)\n",
    "        self.progress_bar.grid(row=4, column=0, columnspan=3, padx=10, pady=10, sticky=\"we\")\n",
    "\n",
    "        # Status Label\n",
    "        ttk.Label(main_frame, textvariable=self.status).grid(row=5, column=0, columnspan=3, padx=10, pady=5)\n",
    "\n",
    "        # Start Button\n",
    "        ttk.Button(main_frame, text=\"Start Transcription\", command=self.start_transcription_thread).grid(row=6, column=0, columnspan=3, padx=10, pady=10)\n",
    "\n",
    "        # Clear Button\n",
    "        ttk.Button(main_frame, text=\"Clear\", command=self.clear_fields).grid(row=7, column=0, columnspan=3, padx=10, pady=5)\n",
    "\n",
    "        # Status Bar\n",
    "        self.status_bar = ttk.Label(self.root, text=\"\", relief=tk.SUNKEN, anchor=\"w\")\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "    def browse_input_folder(self):\n",
    "        \"\"\"Open a dialog to select the input folder.\"\"\"\n",
    "        folder = filedialog.askdirectory()\n",
    "        if folder:\n",
    "            self.input_folder.set(folder)\n",
    "\n",
    "    def browse_output_folder(self):\n",
    "        \"\"\"Open a dialog to select the output folder.\"\"\"\n",
    "        folder = filedialog.askdirectory()\n",
    "        if folder:\n",
    "            self.output_folder.set(folder)\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load the Whisper model.\"\"\"\n",
    "        self.status.set(\"Loading Whisper model...\")\n",
    "        self.root.update_idletasks()\n",
    "        try:\n",
    "            self.model = whisper.load_model(self.model_size.get())\n",
    "            self.status.set(\"Model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load Whisper model: {e}\")\n",
    "            self.status.set(\"Failed to load model.\")\n",
    "\n",
    "    def is_media_file(self, filename):\n",
    "        \"\"\"Check if a file is an audio or video file based on its extension.\"\"\"\n",
    "        media_extensions = [\".mp3\", \".wav\", \".mp4\", \".avi\", \".mkv\", \".flac\", \".m4a\"]\n",
    "        return any(filename.lower().endswith(ext) for ext in media_extensions)\n",
    "\n",
    "    def transcribe_media_file(self, file_path):\n",
    "        \"\"\"Transcribe a media file using Whisper, with optional translation.\"\"\"\n",
    "        try:\n",
    "            translate = self.translate_to_english.get()  # Check if translation is enabled\n",
    "            result = self.model.transcribe(file_path, task=\"translate\" if translate else \"transcribe\")\n",
    "            return result[\"text\"]\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to transcribe {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_transcription(self, file_path, transcription):\n",
    "        \"\"\"Save the transcription as a text file and JSON file.\"\"\"\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_folder = self.output_folder.get()\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Save as text file\n",
    "        output_txt_path = os.path.join(output_folder, f\"{base_name}.txt\")\n",
    "        with open(output_txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(transcription)\n",
    "\n",
    "        # Save as JSON file\n",
    "        output_json_path = os.path.join(output_folder, f\"{base_name}.json\")\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump({\"file_path\": file_path, \"transcription\": transcription}, json_file, indent=4)\n",
    "\n",
    "    def start_transcription_thread(self):\n",
    "        \"\"\"Start the transcription process in a separate thread.\"\"\"\n",
    "        threading.Thread(target=self.start_transcription).start()\n",
    "\n",
    "    def start_transcription(self):\n",
    "        \"\"\"Start the transcription process.\"\"\"\n",
    "        input_folder = self.input_folder.get()\n",
    "        output_folder = self.output_folder.get()\n",
    "\n",
    "        if not input_folder or not output_folder:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select both input and output folders.\")\n",
    "            return\n",
    "\n",
    "        # Get list of media files\n",
    "        media_files = []\n",
    "        for root, _, files in os.walk(input_folder):\n",
    "            for file in files:\n",
    "                if self.is_media_file(file):\n",
    "                    media_files.append(os.path.join(root, file))\n",
    "\n",
    "        if not media_files:\n",
    "            messagebox.showinfo(\"Info\", \"No media files found in the input folder.\")\n",
    "            return\n",
    "\n",
    "        # Process files\n",
    "        total_files = len(media_files)\n",
    "        for i, file_path in enumerate(media_files):\n",
    "            self.status.set(f\"Processing {os.path.basename(file_path)} ({i + 1}/{total_files})...\")\n",
    "            self.progress.set((i + 1) / total_files * 100)\n",
    "            self.root.update_idletasks()\n",
    "\n",
    "            transcription = self.transcribe_media_file(file_path)\n",
    "            if transcription:\n",
    "                self.save_transcription(file_path, transcription)\n",
    "\n",
    "        self.status.set(\"Transcription complete!\")\n",
    "        messagebox.showinfo(\"Info\", \"Transcription completed successfully.\")\n",
    "\n",
    "    def clear_fields(self):\n",
    "        \"\"\"Clear the input and output fields.\"\"\"\n",
    "        self.input_folder.set(\"\")\n",
    "        self.output_folder.set(\"\")\n",
    "        self.status.set(\"Ready\")\n",
    "        self.progress.set(0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = TranscriptionApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907d9904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai-whisper in /home/waseek/.local/lib/python3.10/site-packages (20240930)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper) (8.10.0)\n",
      "Requirement already satisfied: tqdm in /home/waseek/.local/lib/python3.10/site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: triton>=2.0.0 in /home/waseek/.local/lib/python3.10/site-packages (from openai-whisper) (3.2.0)\n",
      "Requirement already satisfied: numba in /home/waseek/.local/lib/python3.10/site-packages (from openai-whisper) (0.61.0)\n",
      "Requirement already satisfied: tiktoken in /home/waseek/.local/lib/python3.10/site-packages (from openai-whisper) (0.8.0)\n",
      "Requirement already satisfied: numpy in /home/waseek/.local/lib/python3.10/site-packages (from openai-whisper) (2.1.3)\n",
      "Requirement already satisfied: torch in /home/waseek/.local/lib/python3.10/site-packages (from openai-whisper) (2.6.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/waseek/.local/lib/python3.10/site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/waseek/.local/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/waseek/.local/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: networkx in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: filelock in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (3.17.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch->openai-whisper) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.3.1.170)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: fsspec in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/waseek/.local/lib/python3.10/site-packages (from torch->openai-whisper) (0.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/waseek/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/waseek/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai-whisper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
